<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Mr-Ben: A Meta-Reasoning Benchmark for LLMs</title>
  <link rel="icon" type="image/x-icon" href="static/images/mr_favicon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Mr-Ben: A Comprehensive Meta-Reasoning Benchmark for Large Language Models</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=bJAQgdUAAAAJ&hl=en" target="_blank">Zhongshen Zeng</a><sup>1</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=fHQKF_AAAAAJ&hl=en&oi=ao" target="_blank">Yinhong Liu</a><sup>2</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?hl=en&user=yCZT5ykAAAAJ" target="_blank">Yingjia Wan</a><sup>2</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=mqrKmvcAAAAJ&hl=en&oi=ao" target="_blank">Jingyao Li</a><sup>1</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=lMnVrgIAAAAJ&hl=en&oi=ao" target="_blank">Pengguang Chen</a><sup>1</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?hl=en&user=jU1A5BYAAAAJ" target="_blank">Jianbo Dai</a><sup>3</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?hl=en&user=PLe5qQEAAAAJ" target="_blank">Yuxuan Yao</a><sup>4</sup>,</span>
                        <span class="author-block"><a href="" target="_blank">Rongwu Xu</a><sup>5</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=kfZ5xAIAAAAJ&hl=en&oi=ao" target="_blank">Zehan Qi</a><sup>5</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=XrkIQQoAAAAJ&hl=en&oi=ao" target="_blank">Wanru Zhao</a><sup>2</sup>,</span>
                        <span class="author-block"><a href="" target="_blank">Linling Shen</a><sup>6</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=uIW6d6AAAAAJ&hl=en&oi=ao" target="_blank">Jianqiao Lu</a><sup>7</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=LRACzBoAAAAJ&hl=en&oi=ao" target="_blank">Haochen Tan</a><sup>4</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=6p0ygKUAAAAJ&hl=en&oi=ao" target="_blank">Yukang Chen</a><sup>1</sup>,</span>
                        <span class="author-block"><a href="" target="_blank">Hao Zhang</a><sup>8</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?hl=en&user=w2I-wNQAAAAJ" target="_blank">Zhan Shi</a><sup>6</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=IlgMpNoAAAAJ&hl=en&oi=ao" target="_blank">Bailin Wang</a><sup>9</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=8b-u3icAAAAJ&hl=en&oi=ao" target="_blank">Zhijiang Guo</a><sup>2,‡</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=XPAkzTEAAAAJ&hl=en&oi=ao" target="_blank">Jiaya Jia</a><sup>1,‡</sup>,</span>
                    </div>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>Chinese University of Hong Kong,</span>
                        <span class="author-block"><sup>2</sup>University of Cambridge,</span>
                        <span class="author-block"><sup>3</sup>University of Edinburgh,</span>
                        <span class="author-block"><sup>4</sup>City University of Hong Kong,</span>
                        <span class="author-block"><sup>5</sup>Tsinghua University,</span>
                        <span class="author-block"><sup>6</sup>University of Texas at Austin,</span>
                        <span class="author-block"><sup>7</sup>University of Hong Kong,</span>
                        <span class="author-block"><sup>8</sup>Nanyang Technological University,</span>
                        <span class="author-block"><sup>9</sup>Massachusetts Institute of Technology</span>
                        <span class="eql-cntrb"><small><br><sup>‡</sup>Corresponding
                                author</small></span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            
                            <span class="link-block">
                                <a href="https://huggingface.co/datasets/Randolphzeng/Mr-Ben" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        &#x1F917;
                                    </span>
                                    <span>Dataset</span>
                                </a>
                            </span>
                            <!-- Github link -->
                            <span class="link-block">
                                <a href="https://github.com/dvlab-research/Mr-Ben" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                </a>
                            </span>

                            <!-- ArXiv abstract Link -->
                            <span class="link-block">
                                <a href="https://arxiv.org/abs/2312.17080" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>arXiv</span>
                                </a>
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large language models (LLMs) have shown increasing capability in problem-solving and decision-making, largely based on the step-by-step chain-of-thought reasoning processes. However, it has been increasingly challenging to evaluate the reasoning capability of LLMs. Concretely, existing <b style="color:red;"> outcome-based</b> benchmarks begin to saturate and become less sufficient to monitor the progress. To this end, we present a <strong style="color:red;"> process-based </strong> benchmark Mr.Ben that demands a meta reasoning skill, where LMs are asked to locate and analyse potential errors in automatically generated reasoning steps. 
            Mr.Ben is a comprehensive benchmark comprising 5,975 questions collected from human experts, covering various subjects such as physics, chemistry, logic, coding, and more.
            By incorporating this approach, Mr.Ben facilitates a multidimensional evaluation of LLM reasoning abilities. We conducted an extensive assessment of open-source and closed-source LLMs using Mr.Ben, which revealed previously unidentified limitations and weaknesses in their meta-reasoning capabilities across different tasks. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop has-text-centered">
          <h2 class="title is-3">Overview</h2>
          <div class="columns is-centered">
              <div class="column is-four-fifths">
                <div class="item">
                  <!-- Your image here -->
                  <img style="width: 100%;" src="static/images/Mr-Ben-Pipeline.jpg" alt="metamath" />
                  <h2 class="subtitle">
                      Figure 1: This is the illustration of the dataset creation pipeline of <i>Mr-Ben</i>.
                  </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img style="width: 100%;" src="static/images/Mr-Ben-Demo.jpg" alt="metamath" />
                    <h2 class="subtitle">
                        Figure 2: Overview of the evaluation paradigm and representative examples in <i>Mr-Ben</i>.
                    </h2>
                </div>         
              </div>
          </div>
      </div>
  </div>
</section>




<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered is-fifths-fifths">
                  <h2 class="title is-3">Evaluation Results</h2>
                  <div class="content has-text-justified">
                      <table>
                          <thead>
                              <tr>
                                  <th>Model</th>
                                  <th>#params</th>
                                  <th>Avg Mr-Score (k=0)</th>
                                  <th>Avg Mr-Score (k=1)</th>
                              </tr>
                              <tr>
                              </tr>
                          </thead>
                          <tbody id="tabResults">
                              <tr class="th">
                                  <td colspan="4" style="text-align: center; font-weight: bold;">
                                      Closed-source Model</td>
                              </tr>
                              <tr>
                                  <td>Claude3-Haiku</td>
                                  <td>-</td>
                                  <td>4.4</td>
                                  <td>3.1</td>
                              </tr>
                              <tr>
                                  <td>GPT-3.5-Turbo</td>
                                  <td>-</td>
                                  <td>4.0</td>
                                  <td>5.5</td>
                              </tr>
                              <tr>
                                  <td>Doubao-pro-4k</td>
                                  <td>-</td>
                                  <td>8.8</td>
                                  <td>11.6</td>
                              </tr>
                              <tr>
                                  <td>Mistral-Large</td>
                                  <td>-</td>
                                  <td>21.3</td>
                                  <td>23.8</td>
                              </tr>
                              <tr>
                                  <td>Yi-Large</td>
                                  <td>-</td>
                                  <td>32.2</td>
                                  <td>32.3</td>
                              </tr>
                              <tr>
                                  <td>Moonshot-v1-8k</td>
                                  <td>-</td>
                                  <td>32.5</td>
                                  <td>33.0</td>
                              </tr>
                              <tr>
                                <td>Claude3.5-Sonnet</td>
                                <td>-</td>
                                <td>33.5</td>
                                <td>37.6</td>
                            </tr>
                              <tr>
                                  <td>Zhipu-GLM-4</td>
                                  <td>-</td>
                                  <td>38.7</td>
                                  <td>39.4</td>
                              </tr>
                              <tr>
                                  <td>GPT-4-Turbo</td>
                                  <td>-</td>
                                  <td><b>43.2</b></td>
                                  <td><b>44.7</b></td>
                              </tr>
                              

                              <tr class="th">
                                  <td colspan="4" style="text-align: center; font-weight: bold;">
                                      Open-source models Small </td>
                              </tr>
                              <tr>
                                  <td>Qwen1.5</td>
                                  <td>1.8B</td>
                                  <td>0.0</td>
                                  <td>0.0</td>
                              </tr>
                              <tr>
                                  <td>Gemma</td>
                                  <td>2B</td>
                                  <td>0.1</td>
                                  <td>0.2</td>
                              </tr>
                              <tr>
                                  <td>Qwen2</td>
                                  <td>1.5B</td>
                                  <td>2.1</td>
                                  <td>5.4</td>
                              </tr>
                              <tr>
                                  <td>Phi-3-Mini</td>
                                  <td>3.8B</td>
                                  <td>11.9</td>
                                  <td>11.0</td>
                              </tr>
                              <tr class="th">
                                  <td colspan="4" style="text-align: center; font-weight: bold;">
                                      Open-source models medium</td>
                              </tr>
                              <tr>
                                  <td>GLM-4</td>
                                  <td>9B</td>
                                  <td>6.7</td>
                                  <td>2.1</td>
                              </tr>
                              <tr>
                                  <td>Deepseek-llm</td>
                                  <td>7B</td>
                                  <td>3.7</td>
                                  <td>3.6</td>
                              </tr>
                              <tr>
                                  <td>Deepseek-Coder</td>
                                  <td>33B</td>
                                  <td>7.0</td>
                                  <td>6.3</td>
                              </tr>
                              <tr>
                                  <td>Deepseek-Coder</td>
                                  <td>7B</td>
                                  <td>10.2</td>
                                  <td>10.2</td>
                              </tr>
                              <tr>
                                  <td>Llama-3</td>
                                  <td>8B</td>
                                  <td>12.2</td>
                                  <td>9.8</td>
                              </tr>
                              <tr>
                                  <td>Yi-1.5</td>
                                  <td>9B</td>
                                  <td>10.2</td>
                                  <td>12.6</td>
                              </tr>
                              
                              <tr class="th">
                                  <td colspan="4" style="text-align: center; font-weight: bold;">
                                      Open-source models large </td>
                              </tr>
                              <tr>
                                  <td>LLaMA-1</td>
                                  <td>65B</td>
                                  <td>50.9</td>
                                  <td>10.6</td>
                              </tr>
                              <tr>
                                  <td>Qwen-1.5</td>
                                  <td>72B</td>
                                  <td>11.5</td>
                                  <td>13.3</td>
                              </tr>
                              <tr>
                                  <td>Deepseek-llm</td>
                                  <td>67B</td>
                                  <td>15.2</td>
                                  <td>16.5</td>
                              </tr>
                              <tr>
                                  <td>Llama-3</td>
                                  <td>70B</td>
                                  <td>19.2</td>
                                  <td>20.2</td>
                              </tr>
                              <tr>
                                <td>Deepseek-coder-v2</td>
                                <td>236B</td>
                                <td>25.0</td>
                                <td>31.7</td>
                            </tr>
                              <tr>
                                  <td>Deepseek-chat-v2</td>
                                  <td>236B</td>
                                  <td>30.2</td>
                                  <td>32.3</td>
                              </tr>
                              <tr>
                                <td>Qwen-2</td>
                                <td>72B</td>
                                <td><b>33.4</b></td>
                                <td><b>34.2</b></td>
                            </tr>
                  </div>
                  </tbody>
                  </table>
              </div>
              <h2 class="subtitle">Table 1:  Evaluation results on Mr.Ben. <br> Note: All models used in our experiments are instruction-finetuned versions, although this is not indicated in their abbreviated names
              </h2>
          </div>
      </div>
  </div>
  </div>
</section>








<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{zeng2024mrben,
        author       = {Zhongshen Zeng and Yinhong Liu and Yingjia Wan and Jingyao Li and Pengguang Chen and Jianbo Dai and Yuxuan Yao and Rongwu Xu and Zehan Qi and Wanru Zhao and Linling Shen and Jianqiao Lu and Haochen Tan and Yukang Chen and Hao Zhang and Zhan Shi and Bailin Wang and Zhijiang Guo and Jiaya Jia},
        title        = {MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models},
        journal      = {CoRR},
        volume       = {abs/2406.13975},
        year         = {2024},
        url          = {https://arxiv.org/abs/2406.13975},
        eprinttype    = {arXiv},
        eprint       = {2406.13975}
      }</code></pre>
    </div>
</section>


<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
